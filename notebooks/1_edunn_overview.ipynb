{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Educational neural networks in Python\n",
    "\n",
    "This code is loosely inspired to [Andrej Karpathy](https://cs.stanford.edu/people/karpathy/)'s excellent but discontinued [Hacker's guide to Neural Networks](http://karpathy.github.io/neuralnets/).\n",
    "\n",
    "This implementation is not a one-to-one translation of the original javascript code into Python, but [there](https://github.com/urwithajit9/HG_NeuralNetwork) [are](https://github.com/johnashu/hackers_guide_to_neural_networks) [many](https://github.com/saiashirwad/Hackers-Guide-To-Neural-Networks-Python) [repositories](https://github.com/pannous/karpathy_neuralnets_python) [on](https://github.com/techniquark/Hacker-s-Guide-to-Neural-Networks-in-Python) [Github](https://github.com/Mutinix/hacker-nn/) that closely match it line-by-line. Use those to follow along the blog post.\n",
    "\n",
    "The purpose of this version is to simplify network definition and automate the computation of forward and backward passes. Both these tasks are exploded and manual (for clarity's sake!) in Karpathy's code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single gate circuit\n",
    "\n",
    "In the example below, we define a network implementing the function f(x,y) = xy.\n",
    "\n",
    "The module `utils.sugar` contains syntactic sugar that allows minimal boilerplate code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a * b =  -3.0\n"
     ]
    }
   ],
   "source": [
    "from utils.sugar import *\n",
    "\n",
    "a, b = const(3, -1)\n",
    "ab = a * b\n",
    "\n",
    "print 'a * b = ', ab.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradients flowing back from output can be computed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = 3.0 (gradient -1.0)\nb = -1.0 (gradient 3.0)\n"
     ]
    }
   ],
   "source": [
    "ab.backprop(grad=1)\n",
    "\n",
    "print 'a = {} (gradient {})'.format(a.val, a.grad)\n",
    "print 'b = {} (gradient {})'.format(b.val, b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without using `utils.sugar`, the code looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a * b =  -3.0\n"
     ]
    }
   ],
   "source": [
    "from gates import *\n",
    "\n",
    "a = Constant(3)\n",
    "b = Constant(-1)\n",
    "ab = MulGate(a, b)\n",
    "\n",
    "print 'a * b = ', ab.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each operation and parameter in a formula is represented by a gate, which abstract a differentiable network unit.\n",
    "\n",
    "Each gate has an associated value and gradient, which can be accessed through the `val` and `grad` members."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minima of a polynomial\n",
    "\n",
    "As an example, let us find the minima of the function $f(x) = 3x^2 - 2x + 1$ by using gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(1.0) = 2.0\nf(0.6) = 0.88\nf(0.44) = 0.7008\nf(0.376) = 0.67213\nf(0.3504) = 0.66754\nf(0.34016) = 0.66681\nf(0.33606) = 0.66669\nf(0.33443) = 0.66667\nf(0.33377) = 0.66667\nf(0.33351) = 0.66667\nf(0.3334) = 0.66667\nf(0.33336) = 0.66667\nf(0.33334) = 0.66667\nf(0.33334) = 0.66667\nf(0.33334) = 0.66667\nf(0.33333) = 0.66667\n"
     ]
    }
   ],
   "source": [
    "x = param(1)  # starting solution\n",
    "f = 3 * x**2 - 2 * x + 1\n",
    "\n",
    "for _ in range(16):\n",
    "    \n",
    "    print 'f({:.5}) = {:.5}'.format(x.val, f.compute())\n",
    "    f.backprop(grad=-1, lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which quickly converges to the single global minima $\\frac{2}{3}$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
