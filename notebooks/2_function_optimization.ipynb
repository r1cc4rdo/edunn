{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Parameter search\n",
    "\n",
    "Given a function of several input values and a starting solution, how should we change the inputs to increase the output value?\n",
    "\n",
    "Three possible strategies are:\n",
    "\n",
    "1. Random local search\n",
    "2. Gradient descent using numerical gradients\n",
    "3. Gradient descent using analytical gradients\n",
    "\n",
    "Strategy (2) and (3) assume the search space to be continuous and differentiable.\n",
    "\n",
    "## Strategy #1: Random Local Search\n",
    "\n",
    "Random search, perturb inputs and accept them if they improve the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial output: -2 * 3 = -6\nFinal output: -1.82 * 2.89 = -5.28\n"
     ]
    }
   ],
   "source": [
    "from random import random\n",
    "\n",
    "best_in = (-2, 3)\n",
    "best_out = best_in[0] * best_in[1]\n",
    "\n",
    "print 'Initial output: {} * {} = {}'.format(best_in[0], best_in[1], best_out)\n",
    "\n",
    "tweak_amount = 0.01\n",
    "for _ in range(100):\n",
    "    \n",
    "    best_plus_noise = tuple(x + tweak_amount * (random() * 2 - 1) for x in best_in)\n",
    "    out = best_plus_noise[0] * best_plus_noise[1]\n",
    "    if out > best_out:\n",
    "        best_in = best_plus_noise\n",
    "        best_out = out\n",
    "        \n",
    "print 'Final output: {:.3} * {:.3} = {:.3}'.format(best_in[0], best_in[1], best_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy #2: Numerical Gradient\n",
    "\n",
    "Perform one step of numerical gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial output: -2 * 3 = -6\nFinal output: -1.97 * 2.98 = -5.8706\n"
     ]
    }
   ],
   "source": [
    "a, b = -2, 3  # initial inputs\n",
    "out = a * b\n",
    "\n",
    "print 'Initial output: {} * {} = {}'.format(a, b, out)\n",
    "\n",
    "eps = 0.0001  # tweak amount\n",
    "da = ((a + eps) * b - out) / eps  # 3.0\n",
    "db = (a * (b + eps) - out) / eps  # -2.0\n",
    "\n",
    "step_size = 0.01\n",
    "a, b = a + step_size * da, b + step_size * db\n",
    "out = a * b\n",
    "\n",
    "print 'Final output: {} * {} = {}'.format(a, b, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy #3: Analytical Gradient\n",
    "\n",
    "Perform one step of gradient descent using analytical derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial output: -2.0 * 3.0 = -6.0\nFinal output: -1.97 * 2.98 = -5.8706\n"
     ]
    }
   ],
   "source": [
    "from utils.sugar import *\n",
    "\n",
    "a, b = param(-2, 3)\n",
    "ab = a * b\n",
    "\n",
    "print 'Initial output: {} * {} = {}'.format(a.val, b.val, ab.compute())\n",
    "ab.backprop(lr=0.01)\n",
    "print 'Final output: {} * {} = {}'.format(a.val, b.val, ab.compute())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
